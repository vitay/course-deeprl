<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Deep Reinforcement Learning - DQN</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../exercises/13-PPO-solution.html" rel="next">
<link href="../exercises/11-Keras-solution.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../exercises/Content.html"><strong>Exercises</strong></a></li><li class="breadcrumb-item"><a href="../exercises/12-DQN-solution.html"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">DQN</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../notes/img/tuc-new.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Deep Reinforcement Learning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text"><strong>Introduction</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.1-Introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.2-Math.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Math basics (optional)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text"><strong>Tabular RL</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.1-Bandits.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bandits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.2-MDP.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Markov Decision Processes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.3-DP.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Dynamic Programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.4-MC.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Monte-Carlo (MC) methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.5-TD.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Temporal Difference learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.6-FA.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Function approximation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.7-NN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Deep learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text"><strong>Model-free RL</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.1-DQN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Deep Q-Learning (DQN)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.2-BeyondDQN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Beyond DQN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.3-PG.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Policy gradient (PG)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.4-A3C.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Advantage actor-critic (A2C, A3C)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.5-DDPG.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Deep Deterministic Policy Gradient (DDPG)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.6-PPO.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Natural gradients (TRPO, PPO)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.7-SAC.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Maximum Entropy RL (SAC)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text"><strong>Model-based RL</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.1-MB.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Model-based RL</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.2-LearnedModels.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Learned world models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.3-AlphaGo.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">AlphaGo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.4-SR.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Successor representations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text"><strong>Outlook</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/5.1-Outlook.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Outlook</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text"><strong>Exercises</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/Content.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">List of exercises</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/Installation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Python installation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/1-Python-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction To Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/2-Numpy-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Numpy and Matplotlib</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/3-Sampling-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/4-Bandits-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bandits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/5-Bandits2-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bandits - part 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/6-DP-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Dynamic programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/7-Gym-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Gym environments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/8-MonteCarlo-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Monte-Carlo control</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/9-TD-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Q-learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/10-Eligibilitytraces-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Eligibility traces</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/11-Keras-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Keras tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/12-DQN-solution.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">DQN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/13-PPO-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">PPO</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#cartpole-balancing-task" id="toc-cartpole-balancing-task" class="nav-link active" data-scroll-target="#cartpole-balancing-task">Cartpole balancing task</a></li>
  <li><a href="#creating-the-model" id="toc-creating-the-model" class="nav-link" data-scroll-target="#creating-the-model">Creating the model</a></li>
  <li><a href="#experience-replay-memory" id="toc-experience-replay-memory" class="nav-link" data-scroll-target="#experience-replay-memory">Experience replay memory</a></li>
  <li><a href="#dqn-agent" id="toc-dqn-agent" class="nav-link" data-scroll-target="#dqn-agent">DQN agent</a>
  <ul class="collapse">
  <li><a href="#init__-initializing-the-agent" id="toc-init__-initializing-the-agent" class="nav-link" data-scroll-target="#init__-initializing-the-agent">1 - <code>__init__()</code>: Initializing the agent</a></li>
  <li><a href="#act-action-selection" id="toc-act-action-selection" class="nav-link" data-scroll-target="#act-action-selection">2 - <code>act()</code>: action selection</a></li>
  <li><a href="#train-training-loop" id="toc-train-training-loop" class="nav-link" data-scroll-target="#train-training-loop">3 - <code>train()</code>: training loop</a></li>
  <li><a href="#update-training-the-value-network" id="toc-update-training-the-value-network" class="nav-link" data-scroll-target="#update-training-the-value-network">4 - <code>update()</code>: training the value network</a></li>
  <li><a href="#test" id="toc-test" class="nav-link" data-scroll-target="#test">5 - <code>test()</code></a></li>
  </ul></li>
  <li><a href="#reward-scaling" id="toc-reward-scaling" class="nav-link" data-scroll-target="#reward-scaling">Reward scaling</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">DQN</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The goal of this exercise is to implement DQN and to apply it to the cartpole balancing problem.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> google.colab</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    IN_COLAB <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    IN_COLAB <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> IN_COLAB:</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span>pip install <span class="op">-</span>U gymnasium pygame moviepy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="948030f3-cdfb-43a1-882a-6140df11639b" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> clear_output</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> deque</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gymnasium <span class="im">as</span> gym</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"gym version:"</span>, gym.__version__)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pygame</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> moviepy.editor <span class="im">import</span> ImageSequenceClip, ipython_display</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>tf.get_logger().setLevel(logging.ERROR)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GymRecorder(<span class="bu">object</span>):</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Simple wrapper over moviepy to generate a .gif with the frames of a gym environment.</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co">    The environment must have the render_mode `rgb_array_list`.</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, env):</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.env <span class="op">=</span> env</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._frames <span class="op">=</span> []</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> record(<span class="va">self</span>, frames):</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="co">"To be called at the end of an episode."</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> frame <span class="kw">in</span> frames:</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._frames.append(np.array(frame))</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> make_video(<span class="va">self</span>, filename):</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        <span class="co">"Generates the gif video."</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>        directory <span class="op">=</span> os.path.dirname(os.path.abspath(filename))</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> os.path.exists(directory):</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>            os.mkdir(directory)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clip <span class="op">=</span> ImageSequenceClip(<span class="bu">list</span>(<span class="va">self</span>._frames), fps<span class="op">=</span><span class="va">self</span>.env.metadata[<span class="st">"render_fps"</span>])</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clip.write_gif(filename, fps<span class="op">=</span><span class="va">self</span>.env.metadata[<span class="st">"render_fps"</span>], loop<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> <span class="va">self</span>._frames</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._frames <span class="op">=</span> []</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> running_average(x, N):</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    kernel <span class="op">=</span> np.ones(N) <span class="op">/</span> N</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.convolve(x, kernel, mode<span class="op">=</span><span class="st">'same'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>gym version: 0.28.1</code></pre>
</div>
</div>
<section id="cartpole-balancing-task" class="level2">
<h2 class="anchored" data-anchor-id="cartpole-balancing-task">Cartpole balancing task</h2>
<p>We are going to use the Cartpole balancing problem, which can be loaded with:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>gym.make(<span class="st">'CartPole-v0'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>States have 4 continuous values (position and speed of the cart, angle and speed of the pole) and 2 discrete outputs (going left or right). The reward is +1 for each transition where the pole is still standing (angle of less than 30° with the vertical).</p>
<p>In CartPole-v0, the episode ends when the pole fails or after 200 steps. In CartPole-v1, the maximum episode length is 500 steps, which is too long for us, so we stick to v0 here.</p>
<p>The maximal (undiscounted) return is therefore 200. Can DQN learn this?</p>
<div class="cell" data-outputid="58411c0e-4248-4e15-9f5e-b284aeea321e" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the environment</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>, render_mode<span class="op">=</span><span class="st">"rgb_array_list"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>recorder <span class="op">=</span> GymRecorder(env)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample the initial state</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>state, info <span class="op">=</span> env.reset()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># One episode:</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>done <span class="op">=</span> <span class="va">False</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>return_episode <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="kw">not</span> done:</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select an action randomly</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    action <span class="op">=</span> env.action_space.sample()</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample a single transition</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    next_state, reward, terminal, truncated, info <span class="op">=</span> env.step(action)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># End of the episode</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    done <span class="op">=</span> terminal <span class="kw">or</span> truncated</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update undiscounted return</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    return_episode <span class="op">+=</span> reward</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Go in the next state</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> next_state</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Return:"</span>, return_episode)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>recorder.record(env.render())</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>video <span class="op">=</span> <span class="st">"videos/cartpole.gif"</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>recorder.make_video(video)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>ipython_display(video)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Return: 29.0
MoviePy - Building file videos/cartpole.gif with imageio.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>                                                   </code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div align="middle"><img src="data:image/gif;base64,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"></div>
</div>
</div>
<p>As the problem is quite simple (4 state variables, 2 actions), DQN can run on a single CPU. However, we advise that you run the notebook on a GPU in Colab to avoid emptying the battery of your laptop too fast or making it too warm as training takes quite a long time.</p>
<p>We will stop from now on to display the cartpole on colab, as we want to go fast.</p>
</section>
<section id="creating-the-model" class="level2">
<h2 class="anchored" data-anchor-id="creating-the-model">Creating the model</h2>
<p>The first step is to create the value network using <code>keras</code>. We will not need anything fancy: a simple fully connected network with 4 input neurons, two hidden layers of 64 neurons each and 2 output neurons will do the trick. ReLU activation functions all along and the Adam optimizer.</p>
<p><strong>Q:</strong> Which loss function should we use? Think about which arguments have to passed to <code>model.compile()</code> and what activation function is required in the output layer.</p>
<p>We will need to create two identical networks: the trained network and the target network. You should therefore create a method that returns a compiled model, so it can be called two times. You should pass it the environment (so the network can know how many input and output neurons it needs) and the learning rate for the Adam optimizer.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_model(env, lr):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ...</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Q:</strong> Implement the method accordingly.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_model(env, lr):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.models.Sequential()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Input(env.observation_space.shape))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Dense(env.action_space.n, activation<span class="op">=</span><span class="st">'linear'</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'mse'</span>, optimizer<span class="op">=</span>tf.keras.optimizers.Adam(learning_rate<span class="op">=</span>lr))</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(model.summary())</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s test this method by creating the trained and target networks.</p>
<p><strong>Important:</strong> every time you call <code>create_model</code>, a new neural network will be instantiated but the previous ones will not be deleted. During this exercise, you may have to create hundreds of networks because of the incremental implementation of DQN: all networks will stay instantiated in the RAM, and your computer/colab tab will freeze after a while. Before creating new networks, delete all existing ones with:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>tf.keras.backend.clear_session()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Q:</strong> Create the trained and target networks. The learning rate does not matter for now. Instantiate the Cartpole environment and print the output of both networks for the initial state (<code>state, info = env.reset()</code>). Are they the same?</p>
<p><em>Hint:</em> <code>model.predict(X, verbose=0)</code> expects an array X of shape (N, 4), with N the number of examples. Here, we have only one example, so make sure to reshape <code>state</code> so it has the shape (1, 4) (otherwise tf will complain).</p>
<div class="cell" data-outputid="5298b903-b14b-4136-d8db-16c74b321199" data-execution_count="5">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>state, info <span class="op">=</span> env.reset()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>state <span class="op">=</span> state.reshape((<span class="dv">1</span>, env.observation_space.shape[<span class="dv">0</span>]))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"State:"</span>, state)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>tf.keras.backend.clear_session()</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>trained_model <span class="op">=</span> create_model(env, <span class="fl">0.001</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>target_model <span class="op">=</span> create_model(env, <span class="fl">0.001</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>trained_prediction <span class="op">=</span> trained_model.predict(state, verbose<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>]</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>target_prediction <span class="op">=</span> target_model.predict(state, verbose<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>]</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">10</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"State:"</span>, state)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Prediction for the trained network:"</span>, trained_prediction)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Prediction for the target network:"</span>, target_prediction)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>State: [[-0.04610259 -0.01609224  0.04184466 -0.04606003]]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-01-18 10:30:13.899822: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro
2024-01-18 10:30:13.899849: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB
2024-01-18 10:30:13.899867: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB
2024-01-18 10:30:13.899901: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2024-01-18 10:30:13.899917: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 64)                320       
                                                                 
 dense_1 (Dense)             (None, 64)                4160      
                                                                 
 dense_2 (Dense)             (None, 2)                 130       
                                                                 
=================================================================
Total params: 4610 (18.01 KB)
Trainable params: 4610 (18.01 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>None
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_3 (Dense)             (None, 64)                320       
                                                                 
 dense_4 (Dense)             (None, 64)                4160      
                                                                 
 dense_5 (Dense)             (None, 2)                 130       
                                                                 
=================================================================
Total params: 4610 (18.01 KB)
Trainable params: 4610 (18.01 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-01-18 10:30:14.573949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>None
----------
State: [[-0.04610259 -0.01609224  0.04184466 -0.04606003]]
Prediction for the trained network: [ 0.02012723 -0.01722453]
Prediction for the target network: [-0.00624603  0.01739823]
----------</code></pre>
</div>
</div>
<p>The target network has the same structure as the trained network, but not the same weights, as they are randomly initialized. We want the target network <span class="math inline">\theta'</span> to have exactly the same weights as the trained weights <span class="math inline">\theta</span>. You can obtain the weights of a network with:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> model.get_weights()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>and set weights using:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>model.set_weights(w)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Q:</strong> Transfer the weights of the trained model to the target model. Compare their predictions for the current state.</p>
<div class="cell" data-outputid="48ea740d-9abd-4d88-942c-f895c27baa25" data-execution_count="6">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>target_model.set_weights(trained_model.get_weights())</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>trained_prediction <span class="op">=</span> trained_model.predict(state, verbose<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>]</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>target_prediction <span class="op">=</span> target_model.predict(state, verbose<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>]</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">10</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"State:"</span>, state)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Prediction for the trained network:"</span>, trained_prediction)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Prediction for the target network:"</span>, target_prediction)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>----------
State: [[-0.04610259 -0.01609224  0.04184466 -0.04606003]]
Prediction for the trained network: [ 0.02012723 -0.01722453]
Prediction for the target network: [ 0.02012723 -0.01722453]
----------</code></pre>
</div>
</div>
</section>
<section id="experience-replay-memory" class="level2">
<h2 class="anchored" data-anchor-id="experience-replay-memory">Experience replay memory</h2>
<p>The second thing that we need is the experience replay memory (or replay buffer). We need a container like a python list where we append (s, a, r, s’, done) transitions (as in Q-learning), but with a maximal capacity: when there are already <span class="math inline">C</span> transitions in the list, one should stop appending to the list, but rather start writing at the beginning of the list.</p>
<p>This would not be very hard to write, but it would take a lot of time and the risk is high to have hard-to-notice bugs.</p>
<p>Here is a basic implementation of the replay buffer using <strong>double-ended queues</strong> (deque). A deque is list with a maximum capacity. If the deque is full, it starts writing again at the beginnning. Exactly what we need. This implementation uses one deque per element in (s, a, r, s’, done), but one could also append the whole transition to a single deque.</p>
<p><strong>Q:</strong> Read the code of the ReplayBuffer and understand what it does.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ReplayBuffer:</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Basic implementation of the experience replay memory using separated deques."</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, max_capacity):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_capacity <span class="op">=</span> max_capacity</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># deques for each element</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.states <span class="op">=</span> deque(maxlen<span class="op">=</span>max_capacity)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.actions <span class="op">=</span> deque(maxlen<span class="op">=</span>max_capacity)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rewards <span class="op">=</span> deque(maxlen<span class="op">=</span>max_capacity)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.next_states <span class="op">=</span> deque(maxlen<span class="op">=</span>max_capacity)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dones <span class="op">=</span> deque(maxlen<span class="op">=</span>max_capacity)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> append(<span class="va">self</span>, state, action, reward, next_state, done):</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store data</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.states.append(state)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.actions.append(action)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rewards.append(reward)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.next_states.append(next_state)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dones.append(done)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sample(<span class="va">self</span>, batch_size):</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Do not return samples if we do not have at least 2*batch_size transitions</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.states) <span class="op">&lt;</span> <span class="dv">2</span><span class="op">*</span>batch_size: </span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> []</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Randomly choose the indices of the samples.</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> <span class="bu">sorted</span>(np.random.choice(np.arange(<span class="bu">len</span>(<span class="va">self</span>.states)), batch_size, replace<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return the corresponding</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [np.array([<span class="va">self</span>.states[i] <span class="cf">for</span> i <span class="kw">in</span> indices]), </span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>                np.array([<span class="va">self</span>.actions[i] <span class="cf">for</span> i <span class="kw">in</span> indices]), </span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>                np.array([<span class="va">self</span>.rewards[i] <span class="cf">for</span> i <span class="kw">in</span> indices]), </span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>                np.array([<span class="va">self</span>.next_states[i] <span class="cf">for</span> i <span class="kw">in</span> indices]), </span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>                np.array([<span class="va">self</span>.dones[i] <span class="cf">for</span> i <span class="kw">in</span> indices])]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Q:</strong> Run a random agent on Cartpole (without rendering) for a few episodes and append each transition to a replay buffer with small capacity (e.g.&nbsp;100). Sample a batch to check that everything makes sense.</p>
<div class="cell" data-outputid="d95112be-68f0-4681-e354-72625f656b75" data-execution_count="8">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">buffer</span> <span class="op">=</span> ReplayBuffer(<span class="dv">100</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> episode <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reset</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    state, info <span class="op">=</span> env.reset()</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    done <span class="op">=</span> <span class="va">False</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample the episode</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> done:</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select an action randomly</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        action <span class="op">=</span> env.action_space.sample()</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform the action</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>        next_state, reward, terminal, truncated, info <span class="op">=</span> env.step(action)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># End of the episode</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>        done <span class="op">=</span> terminal <span class="kw">or</span> truncated</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store the transition</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">buffer</span>.append(state, action, reward, next_state, done)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Go in the next state</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        state <span class="op">=</span> next_state</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample a minibatch</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> <span class="bu">buffer</span>.sample(<span class="dv">10</span>)</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"States:"</span>, batch[<span class="dv">0</span>])</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Actions:"</span>, batch[<span class="dv">1</span>])</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Rewards:"</span>, batch[<span class="dv">2</span>])</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Next states:"</span>, batch[<span class="dv">3</span>])</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Dones:"</span>, batch[<span class="dv">4</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>States: [[-5.0820481e-02 -1.9829975e-01  1.8521409e-01  7.0651567e-01]
 [-2.9969456e-02  1.3707675e-02 -3.1773280e-02 -1.7834282e-02]
 [-1.6467696e-02  4.0724629e-01 -5.4788038e-02 -6.7666495e-01]
 [ 8.8674217e-02  1.1545870e+00 -1.3338995e-01 -1.9483823e+00]
 [-5.4834139e-02 -5.8381045e-01  2.3132987e-02  9.0583807e-01]
 [ 7.2899368e-04  2.1862607e-01  1.4287900e-02 -2.5678131e-01]
 [ 5.1015150e-03  2.3303077e-02  9.1522746e-03  4.0373772e-02]
 [ 6.9507645e-03 -3.6736843e-01  1.2712554e-02  6.3518500e-01]
 [-3.7665710e-02 -5.6538355e-01  8.9652494e-02  9.9486345e-01]
 [-8.3056085e-02 -5.7150620e-01  1.7302851e-01  1.1416848e+00]]
Actions: [0 1 0 0 0 0 1 0 1 1]
Rewards: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Next states: [[-5.4786474e-02 -3.9543873e-01  1.9934440e-01  1.0513088e+00]
 [-2.9695302e-02  2.0927054e-01 -3.2129969e-02 -3.2037029e-01]
 [-8.3227698e-03  2.1292669e-01 -6.8321340e-02 -4.0172252e-01]
 [ 1.1176596e-01  9.6111327e-01 -1.7235760e-01 -1.6998502e+00]
 [-6.6510350e-02 -7.7923793e-01  4.1249748e-02  1.2057012e+00]
 [ 5.1015150e-03  2.3303077e-02  9.1522746e-03  4.0373772e-02]
 [ 5.5675767e-03  2.1829259e-01  9.9597499e-03 -2.4940753e-01]
 [-3.9660427e-04 -5.6266540e-01  2.5416255e-02  9.3184412e-01]
 [-4.8973382e-02 -3.7156767e-01  1.0954977e-01  7.3162979e-01]
 [-9.4486214e-02 -3.7901506e-01  1.9586220e-01  9.0787643e-01]]
Dones: [False False False False False False False False False False]</code></pre>
</div>
</div>
</section>
<section id="dqn-agent" class="level2">
<h2 class="anchored" data-anchor-id="dqn-agent">DQN agent</h2>
<p>Here starts the fun part. There are a lot of things to do here, but you will now whether it works or not only when everything has been (correctly) implemented. So here is a lot of text to read carefully, and then you are on your own.</p>
<p>Reminder from the lecture:</p>
<ul>
<li><p>Initialize value network <span class="math inline">Q_{\theta}</span> and target network <span class="math inline">Q_{\theta'}</span>.</p></li>
<li><p>Initialize experience replay memory <span class="math inline">\mathcal{D}</span> of maximal size <span class="math inline">N</span>.</p></li>
<li><p>for <span class="math inline">t \in [0, T_\text{total}]</span>:</p>
<ul>
<li><p>Select an action <span class="math inline">a_t</span> based on <span class="math inline">Q_\theta(s_t, a)</span>, observe <span class="math inline">s_{t+1}</span> and <span class="math inline">r_{t+1}</span>.</p></li>
<li><p>Store <span class="math inline">(s_t, a_t, r_{t+1}, s_{t+1})</span> in the experience replay memory.</p></li>
<li><p>Every <span class="math inline">T_\text{train}</span> steps:</p>
<ul>
<li><p>Sample a minibatch <span class="math inline">\mathcal{D}_s</span> randomly from <span class="math inline">\mathcal{D}</span>.</p></li>
<li><p>For each transition <span class="math inline">(s_k, a_k, r_k, s'_k)</span> in the minibatch:</p>
<ul>
<li>Compute the target value <span class="math inline">t_k = r_k + \gamma \, \max_{a'} Q_{\theta'}(s'_k, a')</span> using the target network.</li>
</ul></li>
<li><p>Update the value network <span class="math inline">Q_{\theta}</span> on <span class="math inline">\mathcal{D}_s</span> to minimize:</p></li>
</ul>
<p><span class="math display">\mathcal{L}(\theta) = \mathbb{E}_{\mathcal{D}_s}[(t_k - Q_\theta(s_k, a_k))^2]</span></p></li>
<li><p>Every <span class="math inline">T_\text{target}</span> steps:</p>
<ul>
<li>Update target network: <span class="math inline">\theta' \leftarrow \theta</span>.</li>
</ul></li>
</ul></li>
</ul>
<p>Here is the skeleton of the <code>DQNAgent</code> class that you have to write:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DQNAgent:</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, env, create_model, some_parameters):</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.env <span class="op">=</span> env</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: copy the parameters</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: Create the trained and target networks, copy the weights.</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: Create an instance of the replay memory</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> act(<span class="va">self</span>, state):</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: Select an action using epsilon-greedy on the output of the trained model</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> action</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, batch):</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: train the model using the batch of transitions</span></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss <span class="co"># mse on the batch</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>, nb_episodes):</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>        returns <span class="op">=</span> []</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>        losses <span class="op">=</span> []</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: Train the network for the given number of episodes</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> returns, losses</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> test(<span class="va">self</span>):</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: one episode with epsilon temporarily set to 0</span></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nb_steps <span class="co"># Should be 200 after learning</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With this structure, it will be very simple to actually train the DQN on Cartpole:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the environment</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the agent</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>agent <span class="op">=</span> DQNAgent(env, create_model, other_parameters)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the agent</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>returns, losses <span class="op">=</span> agent.train(nb_episodes)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the returns</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>plt.plot(returns)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>plt.plot(running_mean(returns, <span class="dv">10</span>))</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Episodes"</span>)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Returns"</span>)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the losses</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>plt.plot(losses)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Episodes"</span>)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Training loss"</span>)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the network</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>nb_steps <span class="op">=</span> agent.test()</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of steps:"</span>, nb_steps)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>So you “just” have to fill the holes.</p>
<section id="init__-initializing-the-agent" class="level3">
<h3 class="anchored" data-anchor-id="init__-initializing-the-agent">1 - <code>__init__()</code>: Initializing the agent</h3>
<p>In this method, you should first copy the value of the parameters as attributes: learning rate, epsilon, gamma and so on.</p>
<p>Suggested values: gamma = 0.99, learning_rate = 0.001</p>
<p>The second thing to do is to create the trained and target networks (with the same weights) and save them as attributes (the other methods will use them). Do not forget to clear the keras session first, otherwise the RAM will be quickly filled.</p>
<p>The third thing is to create an instance of the ERM. Use a buffer limit of 5000 transitions (should be passed as a parameter).</p>
<p>Do not hesitate to add other stuff as you implementing the other methods (e.g.&nbsp;counters).</p>
</section>
<section id="act-action-selection" class="level3">
<h3 class="anchored" data-anchor-id="act-action-selection">2 - <code>act()</code>: action selection</h3>
<p>We will use a simple <span class="math inline">\epsilon</span>-greedy method for the action selection, as in the previous exercises.</p>
<p>The only difference is that we have to use the trained model to get the greedy action, using <code>trained_model.predict(X, verbose=0)</code>. This will return the Q-value of the two actions left and right. Use <code>argmax()</code> to return the greedy action (with probability 1 - <span class="math inline">\epsilon</span>). <code>env.action_space.sample()</code> should be used for the exploration (do not use the Q-network in that case, it is slow!).</p>
<p><span class="math inline">\epsilon</span> will be scheduled with an initial value of 1.0 and an exponential decay rate of 0.0005 after each action. It is always better to keep a little exploration, even if <span class="math inline">\epsilon</span> has decayed to 0. Keep a minimal value of 0.05 for epsilon.</p>
<p><strong>Q:</strong> Once this has been implemented, run your very slow random agent for 100 episodes to check everything works correctly.</p>
</section>
<section id="train-training-loop" class="level3">
<h3 class="anchored" data-anchor-id="train-training-loop">3 - <code>train()</code>: training loop</h3>
<p>This method will be very similar to the Q-learning agent that you implemented previously. Do not hesitate to copy and paste.</p>
<p>Here is the parts of the DQN algorithm that should be implemented:</p>
<ul>
<li><p>for <span class="math inline">t \in [0, T_\text{total}]</span>:</p>
<ul>
<li><p>Select an action <span class="math inline">a_t</span> based on <span class="math inline">Q_\theta(s_t, a)</span>, observe <span class="math inline">s_{t+1}</span> and <span class="math inline">r_{t+1}</span>.</p></li>
<li><p>Store <span class="math inline">(s_t, a_t, r_{t+1}, s_{t+1})</span> in the experience replay memory.</p></li>
<li><p>Every <span class="math inline">T_\text{train}</span> steps:</p>
<ul>
<li><p>Sample a minibatch <span class="math inline">\mathcal{D}_s</span> randomly from <span class="math inline">\mathcal{D}</span>.</p></li>
<li><p>Update the trained network using <span class="math inline">\mathcal{D}_s</span>.</p></li>
</ul></li>
<li><p>Every <span class="math inline">T_\text{target}</span> steps:</p>
<ul>
<li>Update target network: <span class="math inline">\theta' \leftarrow \theta</span>.</li>
</ul></li>
</ul></li>
</ul>
<p>The main difference with Q-learning is that <code>update()</code> will be called only every <code>T_train = 4</code> steps: the number of updates to the trained network will be 4 times smaller that the number of steps made in the environment. Beware that if the ERM does not have enough transitions yet (less than the batch size), you should not call <code>update()</code>.</p>
<p>Updating the target network (copying the weights of the trained network) should happen every 100 steps. Pass these parameters to the constructor of the agent.</p>
<p>The batch size can be set to 32.</p>
</section>
<section id="update-training-the-value-network" class="level3">
<h3 class="anchored" data-anchor-id="update-training-the-value-network">4 - <code>update()</code>: training the value network</h3>
<p>Using the provided minibatch, one should implement the following part of the DQN algorithm:</p>
<ul>
<li><p>For each transition <span class="math inline">(s_k, a_k, r_k, s'_k)</span> in the minibatch:</p>
<ul>
<li>Compute the target value <span class="math inline">t_k = r_k + \gamma \, \max_{a'} Q_{\theta'}(s'_k, a')</span> using the target network.</li>
</ul></li>
<li><p>Update the value network <span class="math inline">Q_{\theta}</span> on <span class="math inline">\mathcal{D}_s</span> to minimize:</p>
<p><span class="math display">\mathcal{L}(\theta) = \mathbb{E}_{\mathcal{D}_s}[(t_k - Q_\theta(s_k, a_k))^2]</span></p></li>
</ul>
<p>So we just need to define the targets for each transition in the minibatch, and call <code>model.fit()</code> on the trained network to minimize the mse between the current predictions <span class="math inline">Q_\theta(s_k, a_k)</span> and the target.</p>
<p>But we have a problem: the network has two outputs for the actions left and right, but we have only one target for the action that was executed. We cannot compute the mse between a vector with 2 elements and a single value… They must have the same size.</p>
<p>As we want only the train the output neuron corresponding to the action <span class="math inline">a_k</span>, we are going to:</p>
<ol type="1">
<li>Use the trained network to predict the Q-value of both actions <span class="math inline">[Q_\theta(s_k, 0), Q_\theta(s_k, 1)]</span>.</li>
<li>Replace one of the values with the target, for example <span class="math inline">[Q_\theta(s_k, 0), t_k]</span> if the second action was chosen.</li>
<li>Minimize the mse between <span class="math inline">[Q_\theta(s_k, 0), Q_\theta(s_k, 1)]</span> and <span class="math inline">[Q_\theta(s_k, 0), t_k]</span>.</li>
</ol>
<p>That way, the first output neuron has a squared error of 0, so it won’t learn anything. Only the second output neuron will have a non-zero mse and learn.</p>
<p>There are more efficient ways to do this (using masks), but this will do the trick, the drawback being that we have to make a forward pass on the minibatch before calling <code>fit()</code>.</p>
<p>The rest is pretty much the same as for your Q-learning agent. Do not forget that actions leading to a terminal state should only use the reward as a target, not the complete Bellman target <span class="math inline">r + \gamma \max Q</span>.</p>
<p><em>Hint:</em> as we sample a minibatch of 32 transitions, it is faster to call:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>Q_values <span class="op">=</span> np.array(training_model.predict_on_batch(states))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>than:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>Q_values <span class="op">=</span> training_model.predict(states)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>for reasons internal to tensorflow. Note that with tf2, you need to cast the result to numpy arrays as eager mode is now the default.</p>
<p>The method should return the training loss, which is contained in the <code>History</code> object returned by <code>model.fit()</code>. <code>model.fit()</code> should be called for one epoch only, a batch size of 32, and <code>verbose</code> set to 0.</p>
</section>
<section id="test" class="level3">
<h3 class="anchored" data-anchor-id="test">5 - <code>test()</code></h3>
<p>This method should run one episode with epsilon set to 0, without learning. The number of steps should be returned (do not bother discounting with gamma, the goal is to be up for 200 steps).</p>
<p><strong>Q:</strong> Let’s go! Run the agent for 150 episodes and observe how fast it manages to keep the pole up for 200 steps.</p>
<p>Beware that running the same network twice can lead to very different results. In particular, policy collapse (the network was almost perfect, but suddenly crashes and becomes random) can happen. Just be patient.</p>
<p>You can visualize a test trial using the <code>GymRecorder</code>: you just need to set the <code>env</code> attribute of your DQN agent to a new env with the render mode <code>rgb_array_list</code> and record the frames at the end.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DQNAgent:</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, env, create_model, learning_rate, epsilon, epsilon_decay, gamma, batch_size, target_update_period, training_update_period, buffer_limit):</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.env <span class="op">=</span> env</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> epsilon</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon_decay <span class="op">=</span> epsilon_decay</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gamma <span class="op">=</span> gamma</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> batch_size</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_update_period <span class="op">=</span> target_update_period</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.training_update_period <span class="op">=</span> training_update_period</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create the Q-network and the target network</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        tf.keras.backend.clear_session() <span class="co"># start by deleting all existing models to be gentle on the RAM</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> create_model(<span class="va">self</span>.env, <span class="va">self</span>.learning_rate)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_model <span class="op">=</span> create_model(<span class="va">self</span>.env, <span class="va">self</span>.learning_rate)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_model.set_weights(<span class="va">self</span>.model.get_weights())</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create the replay memory</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">buffer</span> <span class="op">=</span> ReplayBuffer(buffer_limit)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> act(<span class="va">self</span>, state):</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># epsilon-greedy</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> <span class="va">self</span>.epsilon: <span class="co"># Random selection</span></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>            action <span class="op">=</span> <span class="va">self</span>.env.action_space.sample()</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>: <span class="co"># Use the Q-network to get the greedy action</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>            action <span class="op">=</span> <span class="va">self</span>.model.predict(state.reshape((<span class="dv">1</span>, env.observation_space.shape[<span class="dv">0</span>])), verbose<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>].argmax()</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Decay epsilon</span></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">*=</span> <span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.epsilon_decay</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> <span class="bu">max</span>(<span class="fl">0.05</span>, <span class="va">self</span>.epsilon)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> action</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, batch):</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the minibatch</span></span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>        states, actions, rewards, next_states, dones <span class="op">=</span> batch </span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict the Q-values in the current state</span></span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> np.array(<span class="va">self</span>.model.predict_on_batch(states))</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict the Q-values in the next state using the target model</span></span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>        next_Q_value <span class="op">=</span> np.array(<span class="va">self</span>.target_model.predict_on_batch(next_states)).<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Terminal states have a value of 0</span></span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>        next_Q_value[dones] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute the target</span></span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.batch_size):</span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a>            targets[i, actions[i]] <span class="op">=</span> rewards[i] <span class="op">+</span> <span class="va">self</span>.gamma <span class="op">*</span> next_Q_value[i]</span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train the model on the minibatch</span></span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>        history <span class="op">=</span> <span class="va">self</span>.model.fit(states, targets, epochs<span class="op">=</span><span class="dv">1</span>, batch_size<span class="op">=</span><span class="va">self</span>.batch_size, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> history.history[<span class="st">'loss'</span>][<span class="dv">0</span>]</span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>, nb_episodes):</span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a>        steps <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a>        returns <span class="op">=</span> []</span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a>        losses <span class="op">=</span> []</span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> episode <span class="kw">in</span> <span class="bu">range</span>(nb_episodes):</span>
<span id="cb30-67"><a href="#cb30-67" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-68"><a href="#cb30-68" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Reset</span></span>
<span id="cb30-69"><a href="#cb30-69" aria-hidden="true" tabindex="-1"></a>            state, info <span class="op">=</span> <span class="va">self</span>.env.reset()</span>
<span id="cb30-70"><a href="#cb30-70" aria-hidden="true" tabindex="-1"></a>            done <span class="op">=</span> <span class="va">False</span></span>
<span id="cb30-71"><a href="#cb30-71" aria-hidden="true" tabindex="-1"></a>            steps_episode <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-72"><a href="#cb30-72" aria-hidden="true" tabindex="-1"></a>            return_episode <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-73"><a href="#cb30-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-74"><a href="#cb30-74" aria-hidden="true" tabindex="-1"></a>            loss_episode <span class="op">=</span> []</span>
<span id="cb30-75"><a href="#cb30-75" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-76"><a href="#cb30-76" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Sample the episode</span></span>
<span id="cb30-77"><a href="#cb30-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> <span class="kw">not</span> done:</span>
<span id="cb30-78"><a href="#cb30-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-79"><a href="#cb30-79" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Select an action </span></span>
<span id="cb30-80"><a href="#cb30-80" aria-hidden="true" tabindex="-1"></a>                action <span class="op">=</span> <span class="va">self</span>.act(state)</span>
<span id="cb30-81"><a href="#cb30-81" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-82"><a href="#cb30-82" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Perform the action</span></span>
<span id="cb30-83"><a href="#cb30-83" aria-hidden="true" tabindex="-1"></a>                next_state, reward, terminal, truncated, info <span class="op">=</span> <span class="va">self</span>.env.step(action)</span>
<span id="cb30-84"><a href="#cb30-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-85"><a href="#cb30-85" aria-hidden="true" tabindex="-1"></a>                <span class="co"># End of the episode</span></span>
<span id="cb30-86"><a href="#cb30-86" aria-hidden="true" tabindex="-1"></a>                done <span class="op">=</span> terminal <span class="kw">or</span> truncated</span>
<span id="cb30-87"><a href="#cb30-87" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb30-88"><a href="#cb30-88" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Store the transition</span></span>
<span id="cb30-89"><a href="#cb30-89" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.<span class="bu">buffer</span>.append(state, action, reward, next_state, done)</span>
<span id="cb30-90"><a href="#cb30-90" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-91"><a href="#cb30-91" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Sample a minibatch</span></span>
<span id="cb30-92"><a href="#cb30-92" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> <span class="va">self</span>.<span class="bu">buffer</span>.sample(<span class="va">self</span>.batch_size)</span>
<span id="cb30-93"><a href="#cb30-93" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb30-94"><a href="#cb30-94" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Train the NN on the minibatch</span></span>
<span id="cb30-95"><a href="#cb30-95" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">len</span>(batch) <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> steps <span class="op">%</span> <span class="va">self</span>.training_update_period <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb30-96"><a href="#cb30-96" aria-hidden="true" tabindex="-1"></a>                    loss <span class="op">=</span> <span class="va">self</span>.update(batch)</span>
<span id="cb30-97"><a href="#cb30-97" aria-hidden="true" tabindex="-1"></a>                    loss_episode.append(loss)</span>
<span id="cb30-98"><a href="#cb30-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-99"><a href="#cb30-99" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Update the target model</span></span>
<span id="cb30-100"><a href="#cb30-100" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> steps <span class="op">&gt;</span> <span class="va">self</span>.target_update_period <span class="kw">and</span> steps <span class="op">%</span> <span class="va">self</span>.target_update_period <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb30-101"><a href="#cb30-101" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.target_model.set_weights(<span class="va">self</span>.model.get_weights())</span>
<span id="cb30-102"><a href="#cb30-102" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-103"><a href="#cb30-103" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Go in the next state</span></span>
<span id="cb30-104"><a href="#cb30-104" aria-hidden="true" tabindex="-1"></a>                state <span class="op">=</span> next_state</span>
<span id="cb30-105"><a href="#cb30-105" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb30-106"><a href="#cb30-106" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Increment time</span></span>
<span id="cb30-107"><a href="#cb30-107" aria-hidden="true" tabindex="-1"></a>                steps <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb30-108"><a href="#cb30-108" aria-hidden="true" tabindex="-1"></a>                steps_episode <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb30-109"><a href="#cb30-109" aria-hidden="true" tabindex="-1"></a>                return_episode <span class="op">+=</span> reward</span>
<span id="cb30-110"><a href="#cb30-110" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb30-111"><a href="#cb30-111" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> done:</span>
<span id="cb30-112"><a href="#cb30-112" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb30-113"><a href="#cb30-113" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-114"><a href="#cb30-114" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Store info</span></span>
<span id="cb30-115"><a href="#cb30-115" aria-hidden="true" tabindex="-1"></a>            returns.append(return_episode)</span>
<span id="cb30-116"><a href="#cb30-116" aria-hidden="true" tabindex="-1"></a>            losses.append(np.mean(loss_episode))</span>
<span id="cb30-117"><a href="#cb30-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-118"><a href="#cb30-118" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Print info</span></span>
<span id="cb30-119"><a href="#cb30-119" aria-hidden="true" tabindex="-1"></a>            clear_output(wait<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-120"><a href="#cb30-120" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'Episode'</span>, episode<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb30-121"><a href="#cb30-121" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">' total steps:'</span>, steps)</span>
<span id="cb30-122"><a href="#cb30-122" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">' length of the episode:'</span>, steps_episode)</span>
<span id="cb30-123"><a href="#cb30-123" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">' return of the episode:'</span>, return_episode)</span>
<span id="cb30-124"><a href="#cb30-124" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">' current loss:'</span>, np.mean(loss_episode))</span>
<span id="cb30-125"><a href="#cb30-125" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">' epsilon:'</span>, <span class="va">self</span>.epsilon)</span>
<span id="cb30-126"><a href="#cb30-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-127"><a href="#cb30-127" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> returns, losses</span>
<span id="cb30-128"><a href="#cb30-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-129"><a href="#cb30-129" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> test(<span class="va">self</span>, render<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb30-130"><a href="#cb30-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-131"><a href="#cb30-131" aria-hidden="true" tabindex="-1"></a>        old_epsilon <span class="op">=</span> <span class="va">self</span>.epsilon</span>
<span id="cb30-132"><a href="#cb30-132" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb30-133"><a href="#cb30-133" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-134"><a href="#cb30-134" aria-hidden="true" tabindex="-1"></a>        state, info <span class="op">=</span> <span class="va">self</span>.env.reset()</span>
<span id="cb30-135"><a href="#cb30-135" aria-hidden="true" tabindex="-1"></a>        nb_steps <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-136"><a href="#cb30-136" aria-hidden="true" tabindex="-1"></a>        done <span class="op">=</span> <span class="va">False</span></span>
<span id="cb30-137"><a href="#cb30-137" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-138"><a href="#cb30-138" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="kw">not</span> done:</span>
<span id="cb30-139"><a href="#cb30-139" aria-hidden="true" tabindex="-1"></a>            action <span class="op">=</span> <span class="va">self</span>.act(state)</span>
<span id="cb30-140"><a href="#cb30-140" aria-hidden="true" tabindex="-1"></a>            next_state, reward, terminal, truncated, info <span class="op">=</span> <span class="va">self</span>.env.step(action)</span>
<span id="cb30-141"><a href="#cb30-141" aria-hidden="true" tabindex="-1"></a>            done <span class="op">=</span> terminal <span class="kw">or</span> truncated</span>
<span id="cb30-142"><a href="#cb30-142" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> next_state</span>
<span id="cb30-143"><a href="#cb30-143" aria-hidden="true" tabindex="-1"></a>            nb_steps <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb30-144"><a href="#cb30-144" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-145"><a href="#cb30-145" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> old_epsilon</span>
<span id="cb30-146"><a href="#cb30-146" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nb_steps</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Exploration with scheduling</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>epsilon_decay <span class="op">=</span> <span class="fl">0.0005</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Discount</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> <span class="fl">0.95</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of episodes</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>nb_episodes <span class="op">=</span> <span class="dv">250</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch size</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.005</span> </span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Size of the replay buffer</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>buffer_limit <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Update of the replay buffer</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>target_update_period <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Training period</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>training_update_period <span class="op">=</span> <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="d920d07f-198c-4591-d6c3-2945fea5c287" data-execution_count="13">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the environment</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the agent</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>agent <span class="op">=</span> DQNAgent(</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    env, create_model, </span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    learning_rate, epsilon, epsilon_decay, gamma, </span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    batch_size, target_update_period, training_update_period, buffer_limit</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the agent</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>returns, losses <span class="op">=</span> agent.train(nb_episodes)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the returns</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>plt.plot(returns)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>plt.plot(running_average(returns, <span class="dv">10</span>))</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Episodes"</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Returns"</span>)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the losses</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>plt.plot(losses)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Episodes"</span>)</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Training loss"</span>)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Episode 250
 total steps: 4047
 length of the episode: 14
 return of the episode: 14.0
 current loss: 131.9358113606771
 epsilon: 0.13212510452461754</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="12-DQN-solution_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="12-DQN-solution_files/figure-html/cell-12-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-outputid="4fbd292b-0f83-4d33-fa86-b103d035f095" data-execution_count="12">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the network</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>, render_mode<span class="op">=</span><span class="st">"rgb_array_list"</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>recorder <span class="op">=</span> GymRecorder(env)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>agent.env <span class="op">=</span> env</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>nb_steps <span class="op">=</span> agent.test()</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>recorder.record(env.render())</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of steps:"</span>, nb_steps)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>video <span class="op">=</span> <span class="st">"videos/cartpole-dqn.gif"</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>recorder.make_video(video)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>ipython_display(video, loop<span class="op">=</span><span class="dv">0</span>, autoplay<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of steps: 9
MoviePy - Building file videos/cartpole-dqn.gif with imageio.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>                                                   </code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div align="middle"><img loop="0" autoplay="1" src="data:image/gif;base64,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"></div>
</div>
</div>
<p><strong>Q:</strong> How does the loss evolve? Does it make sense?</p>
<p><strong>A:</strong> The Q-values are non-stationary: the initial Q-values are very small (the agent fails almost immediately), while they are around 100 after training (200 steps with a reward of +1, but discounted with gamma). The mse increases with the magnitude of the Q-values, so the loss is a poor indicator of the convergence of the network.</p>
</section>
</section>
<section id="reward-scaling" class="level2">
<h2 class="anchored" data-anchor-id="reward-scaling">Reward scaling</h2>
<p><strong>Q:</strong> Do a custom test trial after training (i.e.&nbsp;do not call test(), but copy and adapt its code) and plot the Q-value of the selected action at each time step. Do you think it is a good output for the network? Could it explain why learning is so slow?</p>
<div class="cell" data-outputid="5c417c70-e4d7-4516-b8b7-227cb09c6a46" data-execution_count="13">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>agent.env <span class="op">=</span> env</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># No exploration</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>agent.epsilon <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>state, info <span class="op">=</span> agent.env.reset()</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>done <span class="op">=</span> <span class="va">False</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>Q_values <span class="op">=</span> []</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="kw">not</span> done:</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    action <span class="op">=</span> agent.act(state)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    Q_values.append(agent.model.predict(state.reshape((<span class="dv">1</span>, <span class="dv">4</span>)), verbose<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>][action])</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    next_state, reward, terminal, truncated, info <span class="op">=</span> agent.env.step(action)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    done <span class="op">=</span> terminal <span class="kw">or</span> truncated</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> next_state</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>plt.plot(Q_values)</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Steps"</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Q-value"</span>)</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="12-DQN-solution_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>A:</strong> The predicted Q-values at the beginning of learning are close to 0, as the weights are randomly initialized. They should grow to around 100, which takes a lot of time. If the target Q-values were around 1, learning might be much faster.</p>
<p><strong>Q:</strong> Implement <strong>reward scaling</strong> by dividing the received rewards by a fixed factor of 100 when computing the Bellman targets. That way, the final Q-values will be around 1, what may be much easier to learned.</p>
<p><em>Tip:</em> in order to avoid a huge copy and paste, you can inherit from your DQNAgent and only reimplement the desired function:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ScaledDQNAgent (DQNAgent):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, batch):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Change the content of this function only</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You should reduce a bit the learning rate (e.g.&nbsp;0.001) as the magnitude of the targets has changed.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ScaledDQNAgent(DQNAgent):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, batch):</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the minibatch</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>        states, actions, rewards, next_states, dones <span class="op">=</span> batch </span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict the Q-values in the current state</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> np.array(<span class="va">self</span>.model.predict_on_batch(states))</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict the Q-values in the next state using the target model</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>        next_Q_value <span class="op">=</span> np.array(<span class="va">self</span>.target_model.predict_on_batch(next_states)).<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Terminal states have a value of 0</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        next_Q_value[dones] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute the target</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.batch_size):</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>            targets[i, actions[i]] <span class="op">=</span> rewards[i]<span class="op">/</span><span class="fl">100.</span> <span class="op">+</span> <span class="va">self</span>.gamma <span class="op">*</span> next_Q_value[i]</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train the model on the minibatch</span></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>        history <span class="op">=</span> <span class="va">self</span>.model.fit(states, targets, epochs<span class="op">=</span><span class="dv">1</span>, batch_size<span class="op">=</span><span class="va">self</span>.batch_size, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> history.history[<span class="st">'loss'</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="2c4d228a-f36a-4f13-9ba6-c971ced0925b" data-execution_count="15">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the environment</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the agent</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.002</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>agent <span class="op">=</span> ScaledDQNAgent(env, create_model, learning_rate, epsilon, epsilon_decay, gamma, batch_size, target_update_period, training_update_period, buffer_limit)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the agent</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>returns, losses <span class="op">=</span> agent.train(nb_episodes)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the returns</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>plt.plot(returns)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>plt.plot(running_average(returns, <span class="dv">10</span>))</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Episodes"</span>)</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Returns"</span>)</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the losses</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>plt.plot(losses)</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Episodes"</span>)</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Training loss"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Episode 85
 total steps: 1541
 length of the episode: 16
 return of the episode: 16.0
 current loss: 0.032923879101872444
 epsilon: 0.46269245519982455</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the network</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> gym.make(<span class="st">'CartPole-v0'</span>, render_mode<span class="op">=</span><span class="st">"rgb_array_list"</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>recorder <span class="op">=</span> GymRecorder(env)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>agent.env <span class="op">=</span> env</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>agent.epsilon <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Q-values     </span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>state, info <span class="op">=</span> agent.env.reset()</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>done <span class="op">=</span> <span class="va">False</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>Q_values <span class="op">=</span> []</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="kw">not</span> done:</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    action <span class="op">=</span> agent.act(state)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    Q_values.append(agent.model.predict(state.reshape((<span class="dv">1</span>, <span class="dv">4</span>)), verbose<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>][action])</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    next_state, reward, terminal, truncated, info <span class="op">=</span> agent.env.step(action)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    done <span class="op">=</span> terminal <span class="kw">or</span> truncated</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> next_state</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Q-values</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>plt.plot(Q_values)</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Steps"</span>)</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Q-value"</span>)</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="12-DQN-solution_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-outputid="6a77b08d-7d46-47dd-9ff6-8dca35625747">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>recorder.record(env.render())</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>video <span class="op">=</span> <span class="st">"videos/cartpole-dqn-scaled.gif"</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>recorder.make_video(video)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>ipython_display(video, loop<span class="op">=</span><span class="dv">0</span>, autoplay<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MoviePy - Building file videos/cartpole-dqn-scaled.gif with imageio.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>                                                   </code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div align="middle"><img loop="0" autoplay="1" src="data:image/gif;base64,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"></div>
</div>
</div>
<p><strong>Q:</strong> Depending on the time left and your motivation, vary the different parameters to understand their influence: learning rate, target update frequency, training update frequency, epsilon decay, gamma, etc. Change the size of the network. If you find better hyperparameters than what is proposed, please report them for next year!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../exercises/11-Keras-solution.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Keras tutorial</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../exercises/13-PPO-solution.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-title">PPO</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">Copyright Julien Vitay - <a href="mailto:julien.vitay@informatik.tu-chemnitz.de" class="email">julien.vitay@informatik.tu-chemnitz.de</a></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>