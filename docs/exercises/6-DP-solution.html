<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Deep Reinforcement Learning - 29&nbsp; Dynamic programming</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../exercises/7-Gym-solution.html" rel="next">
<link href="../exercises/5-Bandits2-solution.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-title">Dynamic programming</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../" class="sidebar-logo-link">
      <img src="../notes/img/tuc-new.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Deep Reinforcement Learning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Overview</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true"><strong>Introduction</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.1-Introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.2-Math.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Math basics (optional)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true"><strong>Tabular RL</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.1-Bandits.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bandits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.2-MDP.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Markov Decision Processes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.3-DP.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Dynamic Programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.4-MC.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Monte-Carlo (MC) methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.5-TD.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Temporal Difference learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.6-FA.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Function approximation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.7-NN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Deep learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true"><strong>Model-free RL</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.1-DQN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Deep Q-Learning (DQN)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.2-BeyondDQN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Beyond DQN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.3-PG.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Policy gradient (PG)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.4-A3C.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Advantage actor-critic (A2C, A3C)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.5-DDPG.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Deep Deterministic Policy Gradient (DDPG)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.6-PPO.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Natural gradients (TRPO, PPO)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.7-SAC.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Maximum Entropy RL (SAC)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true"><strong>Model-based RL</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.1-MB.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Model-based RL</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.2-LearnedModels.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Learned world models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.3-AlphaGo.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">AlphaGo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.4-SR.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Successor representations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true"><strong>Outlook</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/5.1-Outlook.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Outlook</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true"><strong>Exercises</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/Content.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">List of exercises</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/Installation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Python installation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/1-Python-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction To Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/2-Numpy-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Numpy and Matplotlib</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/3-Sampling-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/4-Bandits-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bandits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/5-Bandits2-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bandits - part 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/6-DP-solution.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Dynamic programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/7-Gym-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Gym environments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/8-MonteCarlo-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Monte-Carlo control</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/9-TD-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Q-learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/10-Eligibilitytraces-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Eligibility traces</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/11-Keras-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Keras tutorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/12-DQN-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">DQN</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#policy-iteration" id="toc-policy-iteration" class="nav-link active" data-scroll-target="#policy-iteration">Policy Iteration</a>
  <ul class="collapse">
  <li><a href="#iterative-policy-evaluation" id="toc-iterative-policy-evaluation" class="nav-link" data-scroll-target="#iterative-policy-evaluation">Iterative policy evaluation</a></li>
  <li><a href="#policy-iteration-1" id="toc-policy-iteration-1" class="nav-link" data-scroll-target="#policy-iteration-1">Policy iteration</a></li>
  </ul></li>
  <li><a href="#value-iteration" id="toc-value-iteration" class="nav-link" data-scroll-target="#value-iteration">Value iteration</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-title">Dynamic programming</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The goal of this exercise is to find the optimal policy for the recycling robot.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../img/recyclingrobot.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>In this problem, a recycling robot has to search for empty cans to collect (each can defines a “reward” given to the robot). It can also decide to stay where it is to save its battery and wait that somebody brings it a can (which gives less cans in average than actively searching for them).</p>
<p>The robot has two battery levels, <em>high</em> and <em>low</em>.</p>
<ul>
<li><p>In the <em>high</em> level, the robot can either search or wait.</p></li>
<li><p>In the <em>low</em> state, three actions are possible: search, wait and recharge.</p></li>
</ul>
<p>State-action transitions are probabilistic, i.e.&nbsp;they bring the robot in different states based on different probabilities <span class="math inline">\alpha</span> and <span class="math inline">\beta</span>.</p>
<p>This problem defines a finite MDP, with two states <em>high</em> and <em>low</em> corresponding to the battery level. The actions <em>search</em> and <em>wait</em> are possible in the <em>high</em> and <em>low</em> states, while the action <em>recharge</em> is only possible in the <em>low</em> state.</p>
<p><span class="math display">
\begin{aligned}
    \mathcal{S} &amp;=&amp; \{ \text{high}, \text{low} \} \\
    \mathcal{A}(\text{high} ) &amp;=&amp; \{ \text{search}, \text{wait} \} \\
    \mathcal{A}(\text{low} ) &amp;=&amp; \{ \text{search}, \text{wait}, \text{recharge} \}
\end{aligned}
</span></p>
<p>The action <em>search</em> brings on average a reward of <span class="math inline">\mathcal{R}^\text{search}</span>, the action <em>wait</em> a reward of <span class="math inline">\mathcal{R}^\text{wait}</span>, the action <em>recharge</em> brings no reward, but allows to get in the <em>high</em> state.</p>
<p>Note that if the robot decides to search in the <em>low</em> state, there is a probability <span class="math inline">1 - \beta</span> that it totally empties its battery, requiring human intervention. This is punished with a negative reward of -3.</p>
<p>The transition and reward probabilities of each transition is defined in the following table, completely defining a MDP.</p>
<table class="table">
<colgroup>
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 20%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">s</th>
<th style="text-align: center;">s’</th>
<th style="text-align: center;">a</th>
<th style="text-align: center;">p(s’ / s, a)</th>
<th style="text-align: center;">r(s, a, s’)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">high</td>
<td style="text-align: center;">high</td>
<td style="text-align: center;">search</td>
<td style="text-align: center;"><span class="math inline">\alpha</span></td>
<td style="text-align: center;"><span class="math inline">\mathcal{R}^\text{search}</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">high</td>
<td style="text-align: center;">low</td>
<td style="text-align: center;">search</td>
<td style="text-align: center;"><span class="math inline">1 - \alpha</span></td>
<td style="text-align: center;"><span class="math inline">\mathcal{R}^\text{search}</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">low</td>
<td style="text-align: center;">high</td>
<td style="text-align: center;">search</td>
<td style="text-align: center;"><span class="math inline">1 - \beta</span></td>
<td style="text-align: center;"><span class="math inline">-3</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">low</td>
<td style="text-align: center;">low</td>
<td style="text-align: center;">search</td>
<td style="text-align: center;"><span class="math inline">\beta</span></td>
<td style="text-align: center;"><span class="math inline">\mathcal{R}^\text{search}</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">high</td>
<td style="text-align: center;">high</td>
<td style="text-align: center;">wait</td>
<td style="text-align: center;"><span class="math inline">1</span></td>
<td style="text-align: center;"><span class="math inline">\mathcal{R}^\text{wait}</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">high</td>
<td style="text-align: center;">low</td>
<td style="text-align: center;">wait</td>
<td style="text-align: center;"><span class="math inline">0</span></td>
<td style="text-align: center;"><span class="math inline">\mathcal{R}^\text{wait}</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">low</td>
<td style="text-align: center;">high</td>
<td style="text-align: center;">wait</td>
<td style="text-align: center;"><span class="math inline">0</span></td>
<td style="text-align: center;"><span class="math inline">\mathcal{R}^\text{wait}</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">low</td>
<td style="text-align: center;">low</td>
<td style="text-align: center;">wait</td>
<td style="text-align: center;"><span class="math inline">1</span></td>
<td style="text-align: center;"><span class="math inline">\mathcal{R}^\text{wait}</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">low</td>
<td style="text-align: center;">high</td>
<td style="text-align: center;">recharge</td>
<td style="text-align: center;"><span class="math inline">1</span></td>
<td style="text-align: center;"><span class="math inline">0</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">low</td>
<td style="text-align: center;">low</td>
<td style="text-align: center;">recharge</td>
<td style="text-align: center;"><span class="math inline">0</span></td>
<td style="text-align: center;"><span class="math inline">0</span></td>
</tr>
</tbody>
</table>
<p>The goal of this exercise is to find the optimal policy <span class="math inline">\pi^*</span> of the robot, i.e to find for each state the action that should be performed systematically in order to gather the maximum of reward on the long term.</p>
<p>We will apply here two <strong>dynamic programming</strong> methods, policy iteration and value iteration, to solve the Bellman equations.</p>
<p>The Bellman equation for the state function is:</p>
<p><span class="math display">V^{\pi} (s)  = \sum_{a \in \mathcal{A}(s)} \pi(s, a) \, \sum_{s' \in \mathcal{S}} p(s' | s, a) \, [ r(s, a, s') + \gamma \, V^{\pi} (s') ]</span></p>
<p><strong>Q:</strong> On paper, adapt the Bellman equation to the problem. First, for every state <span class="math inline">s</span> and possible action <span class="math inline">a</span>, find the optimal value of the action with the form:</p>
<p><span class="math display">Q^{\pi} (s, a) = f( V^\pi (\text{high}), V^\pi (\text{low}), \alpha, \beta, \gamma, \mathcal{R}^{\text{search}}, \mathcal{R}^{\text{wait}} )</span></p>
<p>Deduce the Bellman equation for the two states <span class="math inline">V^\pi (\text{high})</span> and <span class="math inline">V^\pi (\text{low})</span>.</p>
<p><strong>A:</strong></p>
<p><span class="math display">Q^\pi(\text{high}, \text{search}) = \alpha \, (\mathcal{R }^\text{search} + \gamma \, V^\pi(\text{high} )) + (1- \alpha)\, (\mathcal{R}^\text{search} + \gamma \, V^\pi(\text{low}))</span></p>
<p><span class="math display">Q^\pi(\text{high}, \text{wait}) = \mathcal{R}^\text{wait} + \gamma \, V^\pi(\text{high})</span></p>
<p><span class="math display">Q^\pi(\text{low}, \text{search}) = \beta * (\mathcal{R }^\text{search} + \gamma \,  V^\pi(\text{low})) + (1- \beta) \, (-3 + \gamma \, V^\pi(\text{high}))</span></p>
<p><span class="math display">Q^\pi(\text{low}, \text{wait}) = \mathcal{R}^\text{wait} + \gamma \, V^\pi(\text{low})</span></p>
<p><span class="math display">Q^\pi(\text{low}, \text{recharge}) = \gamma \, V^\pi(\text{high})</span></p>
<p><span class="math display">V^\pi(\text{high}) = \pi(\text{high}, \text{search}) \, Q^\pi(\text{high}, \text{search}) +  \pi(\text{high}, \text{wait}) \, Q^\pi(\text{high}, \text{wait})</span></p>
<p><span class="math display">V^\pi(\text{low}) = \pi(\text{low}, \text{search}) \, Q^\pi(\text{low}, \text{search}) +  \pi(\text{low}, \text{wait}) \, Q^\pi(\text{low}, \text{wait}) + \pi(\text{low}, \text{recharge}) \,  Q^\pi(\text{low}, \text{recharge})</span></p>
<section id="policy-iteration" class="level2">
<h2 class="anchored" data-anchor-id="policy-iteration">Policy Iteration</h2>
<p>Now that we have the Bellman equations for the two states high and low, we can solve them using <strong>iterative policy evaluation</strong> for a fixed policy <span class="math inline">\pi</span>.</p>
<section id="iterative-policy-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="iterative-policy-evaluation">Iterative policy evaluation</h3>
<p>Let’s start by setting the parameters of the MDP. In the rest of the exercise, you will modify these parameters to investigate how it changes the optimal policy.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transition probabilities</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Discount parameter</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> <span class="fl">0.7</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected rewards</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>r_search <span class="op">=</span> <span class="fl">6.0</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>r_wait <span class="op">=</span> <span class="fl">2.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There are many ways to represent states and actions in a MDP. The suggestion for this exercise is to use dictionaries here the keys are the actions’ name and the vaues are indices:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>nb_states <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>nb_actions <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> {<span class="st">'high'</span>: <span class="dv">0</span>, <span class="st">'low'</span>: <span class="dv">1</span>}</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> {<span class="st">'search'</span>: <span class="dv">0</span>, <span class="st">'wait'</span>: <span class="dv">1</span>, <span class="st">'recharge'</span>: <span class="dv">2</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Using dictionaries, you can access numpy arrays with <code>s['high']</code> or <code>a['recharge']</code> instead of 0 and 2, what will make the code readable.</p>
<p>The next step is to initialize numpy arrays where we will store the V and Q values. <code>V</code> will have only two elements for high and low, while <code>Q</code> will be a 2x3 matrix with one element for each state-action pair. Notice that (high, recharge) is not a possible action, so this element will not be be updated.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.zeros(nb_states)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros((nb_states, nb_actions))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can then access the individual values with <code>V[s['high']]</code> or <code>Q[s['low'], a['wait']]</code>.</p>
<p>We can now evaluate a policy <span class="math inline">\pi</span>. In dynamic programming, the policies are deterministic, as we want to estimate the optimal policy.</p>
<p>To implement the policy, we just need to assign the index of an action to each state, i.e.&nbsp;<span class="math inline">\pi(s)</span>. The following cell creates an initial policy <span class="math inline">\pi</span> where the agent <strong>searches</strong> in both states high and low. We here make sure that the array contains integers (0, 1 or 2), but that is not even necessary.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([a[<span class="st">'search'</span>], a[<span class="st">'search'</span>]], dtype<span class="op">=</span><span class="bu">int</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Q:</strong> Evaluate this policy using iterative policy evaluation.</p>
<p>We would normally only need to update the V-value of the two states using:</p>
<p><span class="math display">
     V (s) \leftarrow \sum_{a \in \mathcal{A}(s)} \pi(s, a) \, \sum_{s' \in \mathcal{S}} p(s' | s, a) \, [ r(s, a, s') + \gamma \, V (s') ] \quad \forall s \in \mathcal{S}
</span></p>
<p>The code will be more readable if you first update the Q-values of the 5 state-action pairs:</p>
<p><span class="math display">
     Q (s, a) \leftarrow  \sum_{s' \in \mathcal{S}} p(s' | s, a) \, [ r(s, a, s') + \gamma \, V (s') ] \quad \forall s \in \mathcal{S}
</span></p>
<p>and only then update the two V-values:</p>
<p><span class="math display">
     V (s) \leftarrow \sum_{a \in \mathcal{A}(s)} \pi(s, a) \, Q(s, a)
</span></p>
<p>These updates should normally be applied until the V-values converge. For simplicity, we could decide to simply apply 50 updates or so, and hope that it is enough.</p>
<p>Record the V-value of the two states after each update and plot them.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.zeros(nb_states)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros((nb_states, nb_actions))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>V_high_history <span class="op">=</span> []</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>V_low_history <span class="op">=</span> []</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> alpha <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> (r_search <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'low'</span>]])</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> beta <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta) <span class="op">*</span> (<span class="op">-</span><span class="dv">3</span> <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'high'</span>]])</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'recharge'</span>]] <span class="op">=</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], pi[s[<span class="st">'high'</span>]]]</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], pi[s[<span class="st">'low'</span>]]]</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    V_high_history.append(V[s[<span class="st">'high'</span>]])</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    V_low_history.append(V[s[<span class="st">'low'</span>]])</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Q)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>plt.plot(V_high_history, label<span class="op">=</span><span class="st">"high"</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>plt.plot(V_low_history, label<span class="op">=</span><span class="st">"low"</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[11.28888873  9.90222206  0.        ]
 [ 5.9555554   6.16888873  7.90222206]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6-DP-solution_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Q:</strong> Do the V-values converge? How fast? What do the final values represent? Change the value of <span class="math inline">\gamma</span> and conclude on its importance (do not forget to reset the V and Q arrays to 0!).</p>
<p><strong>A:</strong> The V-values converge quite fast (~15 iterations) to their true value. The high state has a higher value than the low state, as there is no risk in that state to receive the punishment of -3.</p>
<p>The final value is the expected return in that state, that is:</p>
<p><span class="math display">R_t = \sum_{k=0}^\infty \gamma^k \, r_{t+k+1}</span></p>
<p><span class="math inline">\gamma</span> completely changes the scale of the return. Small values of <span class="math inline">\gamma</span> lead to small returns (only a couple of rewards count in the sum), while high values lead to high returns (there are a lot of rewards to be summed, especially because the task is continuing).</p>
<p><strong>Q:</strong> Print the Q-values at the end of the policy evaluation. What would the greedy policy with respect to these Q-values?</p>
<p><strong>Q:</strong> Change the initial policy to this policy and evaluate it. What happens? Compare the final value of the states under both policies. Which one is the best?</p>
<p><strong>A:</strong> The greedy policy w.r.t. the Q-values is searching in high, recharging in low, as the Q-values are maximal for these actions.</p>
<p>If we evaluate this policy, we observe that:</p>
<ul>
<li>the value of both states is higher: this is a better policy, as we collect more return on average.</li>
<li>the greedy policy does not change after the evaluation: we have found the optimal policy already!</li>
</ul>
</section>
<section id="policy-iteration-1" class="level3">
<h3 class="anchored" data-anchor-id="policy-iteration-1">Policy iteration</h3>
<p>Improving the policy is now straightforward. We just to look at the Q-values in each state, and change the policy so that it takes the action with the maximal Q-value. If this does not change the policy (we still take the same actions), we have found the optimal policy, we can stop.</p>
<p><strong>Q:</strong> Implement policy iteration.</p>
<p>Do not forget to reset the V and Q arrays at the beginning of the cell, as well as the original policy.</p>
<p>Use an infinite loop that you will quit when the policy has not changed between two iterations. Something like:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1 - Policy evaluation</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the values</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2 - Policy improvement</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pi <span class="op">!=</span> pi_old:</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Beware:</strong> if you simply assign the policy to another array and modify the policy:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>pi_old <span class="op">=</span> pi</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>pi[s[<span class="st">'high'</span>]] <span class="op">=</span> a[<span class="st">'search'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>pi_old</code> will also change! You need to <code>.copy()</code> the policy.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.zeros(nb_states)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros((nb_states, nb_actions))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([a[<span class="st">'search'</span>], a[<span class="st">'search'</span>]], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>V_high_history <span class="op">=</span> []</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>V_low_history <span class="op">=</span> []</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Policy evaluation</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        Q[s[<span class="st">'high'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> alpha <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> (r_search <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'low'</span>]])</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        Q[s[<span class="st">'high'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        Q[s[<span class="st">'low'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> beta <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta) <span class="op">*</span> (<span class="op">-</span><span class="dv">3</span> <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'high'</span>]])</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        Q[s[<span class="st">'low'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        Q[s[<span class="st">'low'</span>], a[<span class="st">'recharge'</span>]] <span class="op">=</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>        V[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], pi[s[<span class="st">'high'</span>]]]</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>        V[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], pi[s[<span class="st">'low'</span>]]]</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>        V_high_history.append(V[s[<span class="st">'high'</span>]])</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        V_low_history.append(V[s[<span class="st">'low'</span>]])</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Policy improvement</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    pi_old <span class="op">=</span> pi.copy()</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].argmax()</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].argmax()</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Greedy policy after iteration'</span>, t)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'pi(high)='</span>, pi[s[<span class="st">'high'</span>]])</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'pi(low)='</span>, pi[s[<span class="st">'low'</span>]])</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'-'</span>)</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Exit if the policy does not change</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pi[s[<span class="st">'high'</span>]] <span class="op">==</span> pi_old[s[<span class="st">'high'</span>]] <span class="kw">and</span> pi[s[<span class="st">'low'</span>]] <span class="op">==</span> pi_old[s[<span class="st">'low'</span>]]:</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    t <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))   </span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>plt.plot(V_high_history, label<span class="op">=</span><span class="st">"high"</span>)</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>plt.plot(V_low_history, label<span class="op">=</span><span class="st">"low"</span>)</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Greedy policy after iteration 1
pi(high)= 0
pi(low)= 2
-
Greedy policy after iteration 2
pi(high)= 0
pi(low)= 2
-</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6-DP-solution_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="value-iteration" class="level2">
<h2 class="anchored" data-anchor-id="value-iteration">Value iteration</h2>
<p>In value iteration, we merge the policy evaluation and improvement in a single update rule:</p>
<p><span class="math display">
    V (s) \leftarrow \max_{a \in \mathcal{A}(s)} \sum_{s' \in \mathcal{S}} p(s' | s, a) \, [ r(s, a, s') + \gamma \, V (s') ]
</span></p>
<p>The value of state takes the value of its greedy action. The policy is therefore implicitly greedy w.r.t the Q-values.</p>
<p>The algorithm becomes:</p>
<ul>
<li><p>while not converged:</p>
<ul>
<li><p>for all states <span class="math inline">s</span>:</p>
<ul>
<li>Update the value estimates with:</li>
</ul>
<p><span class="math display">
      V (s)  \leftarrow \max_{a \in \mathcal{A}(s)} \sum_{s' \in \mathcal{S}} p(s' | s, a) \, [ r(s, a, s') + \gamma \, V (s') ]
  </span></p></li>
</ul></li>
</ul>
<p><strong>Q:</strong> Modify your previous code to implement value iteration. Use a fixed number of iterations (e.g.&nbsp;50) as in policy evaluation. Visualize the evolution of the V-values and print the greedy policy after each iteration. Conclude.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.zeros(nb_states)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros((nb_states, nb_actions))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([a[<span class="st">'search'</span>], a[<span class="st">'search'</span>]], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>V_high_history <span class="op">=</span> []</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>V_low_history <span class="op">=</span> []</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Policy evaluation</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> alpha <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> (r_search <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'low'</span>]])</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> beta <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta) <span class="op">*</span> (<span class="op">-</span><span class="dv">3</span> <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'high'</span>]])</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'recharge'</span>]] <span class="op">=</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].<span class="bu">max</span>()</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].<span class="bu">max</span>()</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    V_high_history.append(V[s[<span class="st">'high'</span>]])</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    V_low_history.append(V[s[<span class="st">'low'</span>]])</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the greedy policy</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    pi_old <span class="op">=</span> pi.copy()</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].argmax()</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].argmax()</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Greedy policy after iteration'</span>, k)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(high)='</span>, pi[s[<span class="st">'high'</span>]])</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(low)='</span>, pi[s[<span class="st">'low'</span>]])</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"V="</span>, V)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Q="</span>, Q)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))  </span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>plt.plot(V_high_history, label<span class="op">=</span><span class="st">"high"</span>)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>plt.plot(V_low_history, label<span class="op">=</span><span class="st">"low"</span>)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Greedy policy after iteration 49
pi(high)= 0
pi(low)= 2
V= [13.4228186   9.39597296]
Q= [[13.4228186  11.39597296  0.        ]
 [ 7.63221457  8.57718102  9.39597296]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6-DP-solution_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Q:</strong> Change the value of the discount factor <span class="math inline">\gamma =0.3</span> so that the agent becomes short-sighted: it only takes into account the immediate rewards, but forgets about the long-term. Does it change the strategy? Explain why.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transition probabilities</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Discount parameter</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected rewards</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>r_search <span class="op">=</span> <span class="fl">6.0</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>r_wait <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.zeros(nb_states)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros((nb_states, nb_actions))</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([a[<span class="st">'search'</span>], a[<span class="st">'search'</span>]], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>V_high_history <span class="op">=</span> []</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>V_low_history <span class="op">=</span> []</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Policy evaluation</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> alpha <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> (r_search <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'low'</span>]])</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> beta <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta) <span class="op">*</span> (<span class="op">-</span><span class="dv">3</span> <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'high'</span>]])</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'recharge'</span>]] <span class="op">=</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].<span class="bu">max</span>()</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].<span class="bu">max</span>()</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>    V_high_history.append(V[s[<span class="st">'high'</span>]])</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>    V_low_history.append(V[s[<span class="st">'low'</span>]])</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the greedy policy</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    pi_old <span class="op">=</span> pi.copy()</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].argmax()</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].argmax()</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Greedy policy after iteration'</span>, k)</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(high)='</span>, pi[s[<span class="st">'high'</span>]])</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(low)='</span>, pi[s[<span class="st">'low'</span>]])</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"V="</span>, V)</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Q="</span>, Q)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))  </span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>plt.plot(V_high_history, label<span class="op">=</span><span class="st">"high"</span>)</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>plt.plot(V_low_history, label<span class="op">=</span><span class="st">"low"</span>)</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Greedy policy after iteration 49
pi(high)= 0
pi(low)= 1
V= [7.25274725 2.85714286]
Q= [[7.25274725 4.17582418 0.        ]
 [0.71208791 2.85714286 2.17582418]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6-DP-solution_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>A:</strong> the agent now decides to wait in the low state (r=2) instead of recharging (r=0) and then be in the high state (r=6). The agent is so greedy that it cannot stand not getting reward for one step, although he will collect much more reard later.</p>
<p><strong>Q:</strong> Change <span class="math inline">\gamma</span> to 0.99 (far-sighted agent). What does it change and why?</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transition probabilities</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Discount parameter</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> <span class="fl">0.99</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected rewards</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>r_search <span class="op">=</span> <span class="fl">6.0</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>r_wait <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.zeros(nb_states)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros((nb_states, nb_actions))</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([a[<span class="st">'search'</span>], a[<span class="st">'search'</span>]], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>V_high_history <span class="op">=</span> []</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>V_low_history <span class="op">=</span> []</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Policy evaluation</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> alpha <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> (r_search <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'low'</span>]])</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> beta <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta) <span class="op">*</span> (<span class="op">-</span><span class="dv">3</span> <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'high'</span>]])</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'recharge'</span>]] <span class="op">=</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].<span class="bu">max</span>()</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].<span class="bu">max</span>()</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    V_high_history.append(V[s[<span class="st">'high'</span>]])</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    V_low_history.append(V[s[<span class="st">'low'</span>]])</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the greedy policy</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    pi_old <span class="op">=</span> pi.copy()</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].argmax()</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].argmax()</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Greedy policy after iteration'</span>, k)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(high)='</span>, pi[s[<span class="st">'high'</span>]])</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(low)='</span>, pi[s[<span class="st">'low'</span>]])</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"V="</span>, V)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Q="</span>, Q)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))  </span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>plt.plot(V_high_history, label<span class="op">=</span><span class="st">"high"</span>)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>plt.plot(V_low_history, label<span class="op">=</span><span class="st">"low"</span>)</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Greedy policy after iteration 49
pi(high)= 0
pi(low)= 2
V= [141.37219244 137.82818773]
Q= [[141.37219244 139.82818773   0.        ]
 [135.92647479 136.31962304 137.82818773]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6-DP-solution_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>A:</strong> The optimal policy stays the same (search in high, recharge in low) but the V values grow very high. The difference between the values of the high and low state is comparatively very small: the high state is always only one action away from the low state, it is nothing with such a high gamma.</p>
<p><strong>Q:</strong> Change the parameters to:</p>
<p><span class="math display">\alpha = 0.01 \quad \beta = 0.2 \quad \gamma = 0.7 \quad \mathcal{R}^{\text{search}} = 6 \quad  \mathcal{R}^{\text{wait}} = 5</span></p>
<p>Find the optimal policy. What is the optimal action to be taken in the state <em>high</em>, although the probability to stay in this state is very small? Why?</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transition probabilities</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Discount parameter</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> <span class="fl">0.7</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected rewards</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>r_search <span class="op">=</span> <span class="fl">6.0</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>r_wait <span class="op">=</span> <span class="fl">5.0</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.zeros(nb_states)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros((nb_states, nb_actions))</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([a[<span class="st">'search'</span>], a[<span class="st">'search'</span>]], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>V_high_history <span class="op">=</span> []</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>V_low_history <span class="op">=</span> []</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Policy evaluation</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> alpha <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> (r_search <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'low'</span>]])</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> beta <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta) <span class="op">*</span> (<span class="op">-</span><span class="dv">3</span> <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'high'</span>]])</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'recharge'</span>]] <span class="op">=</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].<span class="bu">max</span>()</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].<span class="bu">max</span>()</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    V_high_history.append(V[s[<span class="st">'high'</span>]])</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>    V_low_history.append(V[s[<span class="st">'low'</span>]])</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the greedy policy</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    pi_old <span class="op">=</span> pi.copy()</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].argmax()</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].argmax()</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Greedy policy after iteration'</span>, k)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(high)='</span>, pi[s[<span class="st">'high'</span>]])</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(low)='</span>, pi[s[<span class="st">'low'</span>]])</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"V="</span>, V)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Q="</span>, Q)</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))  </span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>plt.plot(V_high_history, label<span class="op">=</span><span class="st">"high"</span>)</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>plt.plot(V_low_history, label<span class="op">=</span><span class="st">"low"</span>)</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Greedy policy after iteration 49
pi(high)= 0
pi(low)= 1
V= [17.67371571 16.66666637]
Q= [[17.67371571 17.37160091  0.        ]
 [11.030614   16.66666637 12.37160091]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6-DP-solution_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>A:</strong> the agent now decides to wait in the low state and accumulate quite a lot of rewards (r=5, compared to 6 while searching). But it is still worth searching in the high state: even if we transition immediately into low with 99% probability, one still gets 6 instead of 5, so the return is higher than when waiting in high.</p>
<p><strong>Q:</strong> Find a set of parameters where it would be optimal to search while in the <em>low</em> state.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transition probabilities</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Discount parameter</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> <span class="fl">0.7</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected rewards</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>r_search <span class="op">=</span> <span class="fl">10.0</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>r_wait <span class="op">=</span> <span class="fl">5.0</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> np.zeros(nb_states)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>Q <span class="op">=</span> np.zeros((nb_states, nb_actions))</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.array([a[<span class="st">'search'</span>], a[<span class="st">'search'</span>]], dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>V_high_history <span class="op">=</span> []</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>V_low_history <span class="op">=</span> []</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Policy evaluation</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> alpha <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> (r_search <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'low'</span>]])</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'high'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'search'</span>]] <span class="op">=</span> beta <span class="op">*</span> (r_search <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta) <span class="op">*</span> (<span class="op">-</span><span class="dv">3</span> <span class="op">+</span> gamma<span class="op">*</span>V[s[<span class="st">'high'</span>]])</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'wait'</span>]] <span class="op">=</span> r_wait <span class="op">+</span> gamma <span class="op">*</span> V[s[<span class="st">'low'</span>]]</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    Q[s[<span class="st">'low'</span>], a[<span class="st">'recharge'</span>]] <span class="op">=</span> gamma <span class="op">*</span> V[s[<span class="st">'high'</span>]]</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].<span class="bu">max</span>()</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>    V[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].<span class="bu">max</span>()</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>    V_high_history.append(V[s[<span class="st">'high'</span>]])</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>    V_low_history.append(V[s[<span class="st">'low'</span>]])</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the greedy policy</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>    pi_old <span class="op">=</span> pi.copy()</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'high'</span>]] <span class="op">=</span> Q[s[<span class="st">'high'</span>], :<span class="dv">2</span>].argmax()</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>    pi[s[<span class="st">'low'</span>]] <span class="op">=</span> Q[s[<span class="st">'low'</span>], :].argmax()</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Greedy policy after iteration'</span>, k)</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(high)='</span>, pi[s[<span class="st">'high'</span>]])</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'pi(low)='</span>, pi[s[<span class="st">'low'</span>]])</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"V="</span>, V)</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Q="</span>, Q)</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))  </span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>plt.plot(V_high_history, label<span class="op">=</span><span class="st">"high"</span>)</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>plt.plot(V_low_history, label<span class="op">=</span><span class="st">"low"</span>)</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Greedy policy after iteration 49
pi(high)= 0
pi(low)= 0
V= [28.03236199 25.7375694 ]
Q= [[28.03236199 24.62265325  0.        ]
 [25.7375694  23.01629844 19.62265325]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6-DP-solution_files/figure-html/cell-13-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../exercises/5-Bandits2-solution.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Bandits - part 2</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../exercises/7-Gym-solution.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-title">Gym environments</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">Copyright 2022, Julien Vitay - <a href="mailto:julien.vitay@informatik.tu-chemnitz.de" class="email">julien.vitay@informatik.tu-chemnitz.de</a></div>
  </div>
</footer>



<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>