{"headings":["limits-of-tabular-rl","tabular-reinforcement-learning","tabular-reinforcement-learning-1","tabular-reinforcement-learning-2","tabular-rl-cannot-learn-to-play-video-games","continuous-action-spaces","continuous-action-spaces-1","function-approximation","feature-vectors","feature-vectors-1","feature-vectors-2","state-value-approximation","linear-approximation-of-state-value-functions","learning-the-state-value-approximation","learning-the-state-value-approximation-1","learning-the-state-value-approximation-2","learning-the-state-value-approximation-3","linear-approximation","function-approximation-with-sampling","gradient-monte-carlo-algorithm-for-value-estimation","semi-gradient-temporal-difference-algorithm-for-value-estimation","function-approximation-for-q-values","q-learning-with-function-approximation","feature-construction","feature-construction-1","why-do-we-need-to-choose-features","feature-coding","linear-approximation-1","polynomials","polynomials-1","polynomials-2","polynomials-3","fourier-transforms","fourier-transforms-1","polynomial-vs.-fourier-basis","discrete-coding","coarse-coding","tile-coding","radial-basis-functions-rbf","radial-basis-functions-rbf-1","summary-of-function-approximation"],"entries":[]}