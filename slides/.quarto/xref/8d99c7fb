{"entries":[],"headings":["markov-decision-process","markov-decision-process-mdp","finite-state-machine-fsm","markov-chain-mc","markov-property","markov-property-1","markov-property-2","state-transition-matrix","markov-reward-process-mrp","expected-reward","return","discount-factor","markov-decision-process-mdp-1","markov-decision-process-mdp-2","transition-and-reward-probabilities","the-markov-property-for-a-mdp","return-1","return-2","why-the-reward-on-the-long-term","why-the-reward-on-the-long-term-1","example-the-cartpole-balancing-task","example-the-recycling-robot-mdp","example-the-recycling-robot-mdp-1","example-the-recycling-robot-mdp-2","the-policy","goal-of-reinforcement-learning","bellman-equations","value-functions","value-functions-1","value-functions-2","value-functions-3","the-v-and-q-value-functions-are-inter-dependent","values-and-immediate-rewards","the-v-and-q-value-functions-are-inter-dependent-1","bellman-equation-for-vpi","bellman-equation-for-qpi","bellman-optimality-equations","optimal-policy","optimal-value-functions","bellman-optimality-equations-1","bellman-optimality-equations-2","obtaining-the-optimal-policy-from-the-optimal-values","bellman-optimality-equations-for-v-or-q","how-to-solve-the-bellman-equations","key-idea-of-reinforcement-learning-generalized-policy-iteration","different-notations-in-rl"]}