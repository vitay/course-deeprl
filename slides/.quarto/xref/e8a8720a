{"entries":[],"headings":["outline","n-armed-bandits","evaluative-feedback","n-armed-bandits-1","n-armed-bandits-2","n-armed-bandits-3","sampling-based-evaluation","sampling-based-evaluation-1","online-evaluation","online-evaluation-1","online-evaluation-2","online-evaluation-3","action-selection","action-selection-1","action-selection-2","greedy-action-selection","greedy-action-selection-1","problem-with-greedy-action-selection","problem-with-greedy-action-selection-1","problem-with-greedy-action-selection-2","problem-with-greedy-action-selection-3","exploration-exploitation-dilemma","epsilon-greedy-action-selection","epsilon-greedy-action-selection-1","softmax-action-selection","softmax-action-selection-1","example-of-action-selection-for-the-10-armed-bandit","greedy-action-selection-2","epsilon-greedy-action-selection-2","softmax-action-selection-2","greedy-vs.-epsilon-greedy","softmax-vs.-epsilon-greedy","exploration-schedule","exploration-schedule-1","optimistic-initial-values","optimistic-initial-values-1","reinforcement-comparison","reinforcement-comparison-1","reinforcement-comparison-2","gradient-bandit-algorithm","gradient-bandit-algorithm-1","gradient-bandit-algorithm-2","upper-confidence-bound-action-selection","upper-confidence-bound-action-selection-1","upper-confidence-bound-action-selection-2","upper-confidence-bound-action-selection-3","summary-of-evaluative-feedback-methods","contextual-bandits","contextual-bandits-1","contextual-bandits-2"]}